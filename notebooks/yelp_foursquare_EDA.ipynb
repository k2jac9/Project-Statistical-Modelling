{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import folium\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load stations dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv('stations.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foursquare iteration over bike tations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "FSQ_API_URL = \"https://api.foursquare.com/v3/places/search\"\n",
    "\n",
    "def getNearbyPOI(latitude, longitude, radius=1000, open_now=True):\n",
    "    \"\"\"\n",
    "    Retrieves nearby points of interest using Foursquare API.\n",
    "\n",
    "    Args:\n",
    "    latitude (float): Latitude of the location.\n",
    "    longitude (float): Longitude of the location.\n",
    "    radius (int, optional): Search radius in meters. Default is 1000.\n",
    "    open_now (bool, optional): Whether to search only for places that are open now. Default is True.\n",
    "    sort (str, optional): Sorting method of the results. Default is 'DISTANCE'.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries with POI information.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If the API request fails.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"radius\": str(radius),\n",
    "        \"ll\": f\"{latitude},{longitude}\",\n",
    "        \"open_now\": \"true\" if open_now else \"false\"\n",
    "    }\n",
    "\n",
    "    # Securely load the API key\n",
    "    api_key = os.getenv('FSQ_key')\n",
    "    if not api_key:\n",
    "        raise Exception(\"API key not found\")\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": api_key\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(FSQ_API_URL, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return json.loads(response.text)\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"Error fetching data: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# nearby_pois = getNearbyPOI(40.7128, -74.0060)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe named 'df_fspoi' that consolidates details of both stations and points of interest. This dataframe includes columns for station name, latitude, longitude, and usage, as well as columns for the name, distance, rating, and address of each point of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fspoi = pd.DataFrame(columns=['station', 'usage', 'total_bikes', 'poi_name', 'poi_distance', 'poi_address'])\n",
    "rows_to_append = []  # Create an empty list to store rows\n",
    "\n",
    "for index, station in tqdm(stations_df.iterrows(), total=len(stations_df), desc=\"Processing Stations\"):\n",
    "    myjson = getNearbyPOI(station['latitude'], station['longitude'])\n",
    "    for business in myjson['results']:\n",
    "        fs_info_data = {\n",
    "            \"name\": business['name'],\n",
    "            \"distance\": business['distance'],\n",
    "            \"address\": business['location']['formatted_address']\n",
    "        }\n",
    "        row = [station['name'], station['usage_percentage'], station['total_bikes'], fs_info_data['name'],\n",
    "               fs_info_data['distance'], fs_info_data['address']]\n",
    "        rows_to_append.append(row)  # Append rows to the list\n",
    "\n",
    "df_fspoi = pd.concat([df_fspoi, pd.DataFrame(rows_to_append, columns=df_fspoi.columns)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fspoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm saving the dataframe to CSV for the next section\n",
    "df_fspoi.to_csv('FourSquarePOI.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fspoi.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fspoi.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fspoi.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning - checking for duplicates in points of interest is will be important, since stations are within 300 metres. Stations have no duplicates as checked earlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_fspoi.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (1000m) for all the bike stations in your city of choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "print (\"libraries imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyYelp(latitude, longitude):\n",
    "    \n",
    "    \n",
    "    # Define my API Key, My Endpoint, and My Header\n",
    "    API_KEY = os.getenv('YELP_key')\n",
    "    ENDPOINT = 'https://api.yelp.com/v3/businesses/search'\n",
    "    HEADERS = {'Authorization': 'bearer %s' % API_KEY}\n",
    "   \n",
    "    \n",
    "    # BUSINESS SEARCH PARAMETERS \n",
    "    PARAMETERS = {'latitude': f\"{latitude}\",\n",
    "              'longitude': f\"{longitude}\",\n",
    "              'radius': 1000}   \n",
    "    \n",
    "    \n",
    "    # Make a request to the Yelp API\n",
    "    response = requests.get(url = ENDPOINT,\n",
    "                        params = PARAMETERS,\n",
    "                        headers = HEADERS)   \n",
    "    \n",
    "    yelp_data = response.json() \n",
    "    \n",
    "    return yelp_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming stations_df is already defined and populated\n",
    "df_yelp_poi = pd.DataFrame(columns=['station', 'usage', 'total_bikes', 'poi_name', 'poi_distance', 'poi_address'])\n",
    "rows_to_append = []\n",
    "\n",
    "for index, station in tqdm(stations_df.iterrows(), total=len(stations_df), desc=\"Processing Stations\"):\n",
    "    yelpjson = getNearbyYelp(station['latitude'], station['longitude'])\n",
    "    \n",
    "    # Debugging: Print out the response to check its structure\n",
    "    print(yelpjson)\n",
    "\n",
    "    # Proceed only if 'businesses' key exists\n",
    "    if 'businesses' in yelpjson:\n",
    "        for business in yelpjson['businesses']:\n",
    "            yelp_info_data = {\n",
    "                \"name\": business['name'],\n",
    "                \"distance\": business['distance'],\n",
    "                \"address\": business['location']['address1']\n",
    "            }\n",
    "            row = [station['name'], station['usage_percentage'], station['total_bikes'], yelp_info_data['name'],\n",
    "                   yelp_info_data['distance'], yelp_info_data['address']]\n",
    "            rows_to_append.append(row)\n",
    "    else:\n",
    "        print(f\"Warning: No 'businesses' key in response for station {station['name']}\")\n",
    "\n",
    "df_yelp_poi = pd.concat([df_yelp_poi, pd.DataFrame(rows_to_append, columns=df_yelp_poi.columns)], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_poi.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_poi.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning - checking for duplicates in points of interest is to be expected, since some stations are within 2000 metres of others. Stations have no duplicates as checked earlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning - checking for null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_yelp_poi.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yelp_poi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm saving the dataframe to CSV for the next section\n",
    "df_yelp_poi.to_csv('YelpPOI.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which API provided you with more complete data? Provide an explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generally yelp seems to provide a higher quality of information considering they give a rating to the businesses involved, also they simply have many more businesses tracked as points of interest in Fort Lauderdale than foursquare does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 restaurants according to their rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define constants\n",
    "YELP_API_KEY = os.getenv('YELP_key')\n",
    "YELP_API_URL = \"https://api.yelp.com/v3/businesses/search\"\n",
    "RESULTS_LIMIT = 20\n",
    "RADIUS_METERS = 1000  # Set the radius to 1000 meters\n",
    "\n",
    "def get_top_restaurants_and_poi(location, api_key):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}'\n",
    "    }\n",
    "\n",
    "    # Define common parameters\n",
    "    common_params = {\n",
    "        'location': location,\n",
    "        'limit': RESULTS_LIMIT,\n",
    "        'open_now': True,\n",
    "        'radius': RADIUS_METERS  # Add the 'radius' parameter with the specified value\n",
    "    }\n",
    "\n",
    "    # Define separate parameters for restaurants and POI\n",
    "    restaurant_params = {\n",
    "        'term': 'restaurants',\n",
    "        **common_params\n",
    "    }\n",
    "\n",
    "    poi_params = {\n",
    "        'term': 'points of interest',\n",
    "        **common_params\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Retrieve top-rated restaurants\n",
    "        response_restaurants = requests.get(YELP_API_URL, headers=headers, params=restaurant_params)\n",
    "        response_restaurants.raise_for_status()\n",
    "\n",
    "        data = response_restaurants.json()\n",
    "        restaurants = data.get('businesses', [])\n",
    "\n",
    "        # Sort restaurants by rating, descending\n",
    "        top_restaurants = sorted(restaurants, key=lambda x: x.get('rating', 0), reverse=True)\n",
    "\n",
    "        # Create a DataFrame for restaurants\n",
    "        restaurant_df = pd.DataFrame(top_restaurants[:RESULTS_LIMIT])\n",
    "        restaurant_df = restaurant_df[['name', 'rating', 'coordinates']]\n",
    "\n",
    "        # Extract 'latitude' and 'longitude' from the 'coordinates' column\n",
    "        restaurant_df['latitude'] = restaurant_df['coordinates'].apply(lambda x: x['latitude'])\n",
    "        restaurant_df['longitude'] = restaurant_df['coordinates'].apply(lambda x: x['longitude'])\n",
    "\n",
    "        # Save restaurant_df as CSV if needed\n",
    "        #restaurant_csv_file_path = '../data/restaurant_data.csv'\n",
    "        #restaurant_df.to_csv(restaurant_csv_file_path, index=False)\n",
    "\n",
    "        # Retrieve top-rated POI\n",
    "        response_poi = requests.get(YELP_API_URL, headers=headers, params=poi_params)\n",
    "        response_poi.raise_for_status()\n",
    "\n",
    "        data = response_poi.json()\n",
    "        raw_poi = data.get('businesses', [])\n",
    "\n",
    "        # Create a DataFrame for POI\n",
    "        raw_poi_df = pd.DataFrame(raw_poi[:RESULTS_LIMIT])\n",
    "        raw_poi_df = raw_poi_df[['name', 'rating', 'coordinates']]\n",
    "\n",
    "        # Extract 'latitude' and 'longitude' from the 'coordinates' column\n",
    "        raw_poi_df['latitude'] = raw_poi_df['coordinates'].apply(lambda x: x['latitude'])\n",
    "        raw_poi_df['longitude'] = raw_poi_df['coordinates'].apply(lambda x: x['longitude'])\n",
    "\n",
    "        # Drop the 'coordinates' column from raw_poi_df\n",
    "        raw_poi_df.drop('coordinates', axis=1, inplace=True)\n",
    "\n",
    "        # Concatenate raw_poi_df and restaurant_df into poi_df\n",
    "        poi_df = pd.concat([raw_poi_df, restaurant_df], ignore_index=True)\n",
    "\n",
    "        # Save poi_df as CSV\n",
    "        csv_file_path = '../data/poi_data.csv'\n",
    "        poi_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "        return restaurant_df  # Return restaurant_df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "location = 'Paris'\n",
    "restaurant_df = get_top_restaurants_and_poi(location, YELP_API_KEY)  # Assign the returned DataFrame to restaurant_df\n",
    "\n",
    "               \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 10 restaurants with only 'name' and 'rating' columns\n",
    "print(\"Top 10 Restaurants:\")\n",
    "for idx, row in restaurant_df.head(10).iterrows():\n",
    "    name = row['name']\n",
    "    rating = row['rating']\n",
    "    # Use str.ljust to left-align the numbers with a width of 2\n",
    "    idx_str = str(idx + 1).ljust(2)\n",
    "    print(f\"{idx_str}. Name: {name}, Rating: {rating:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 restaurants according to Yelp ratings for Fort Lauderdale are listed above. Yelp documentation indicates that the: \"rating sort is NOT strictly sorted by the rating value, but by an adjusted rating value that takes into account the number of ratings, similar to a Bayesian average. This is to prevent skewing results to businesses with a single review\". Due to this (favourable) detail of the Yelp rating sort, I felt is was suitable to just show the top 10 results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Restaurants:\n",
    "1 . Name: Grand Hôtel du Palais Royal, Rating: 4.5\n",
    "2 . Name: De Voltaire à Rousseau, Rating: 4.5\n",
    "3 . Name: Grand Bay Café, Rating: 4.5\n",
    "4 . Name: La Tour de Montlhéry ou chez Denise, Rating: 4.0\n",
    "5 . Name: Le Terminus du Châtelet, Rating: 4.0\n",
    "6 . Name: Au Pied de Cochon, Rating: 3.5\n",
    "7 . Name: Le Tambour, Rating: 3.5\n",
    "8 . Name: Chacha, Rating: 3.0\n",
    "9 . Name: Le Départ Saint Michel, Rating: 3.0 10. Name: Le Buci, Rating: 3.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
